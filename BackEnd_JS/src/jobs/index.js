import cron from 'node-cron';
import { refreshPopularProducts } from './refreshPrices.job.js';
import { checkPriceAlerts } from './checkAlerts.job.js';
import { cleanupOldData } from './cleanupOldData.job.js';
import { syncCrawlerData } from './syncCrawlerData.job.js';
import { logger } from '../utils/logger.js';

export function startJobs() {
  // Crawl and sync products every 12 hours
  cron.schedule('0 */12 * * *', async () => {
    logger.info('ğŸ•·ï¸ Starting crawler data sync...');
    try {
      await syncCrawlerData();
      logger.info('âœ… Crawler data sync completed');
    } catch (error) {
      logger.error('âŒ Crawler data sync failed:', error);
    }
  });
  
  // Refresh prices every 6 hours
  cron.schedule('0 */6 * * *', async () => {
    logger.info('ğŸ”„ Starting scheduled price refresh...');
    try {
      await refreshPopularProducts();
      logger.info('âœ… Price refresh completed');
    } catch (error) {
      logger.error('âŒ Price refresh failed:', error);
    }
  });
  
  // Check price alerts every hour
  cron.schedule('0 * * * *', async () => {
    logger.info('ğŸ”” Checking price alerts...');
    try {
      await checkPriceAlerts();
      logger.info('âœ… Price alerts checked');
    } catch (error) {
      logger.error('âŒ Price alert check failed:', error);
    }
  });
  
  // Cleanup old data daily at 3 AM
  cron.schedule('0 3 * * *', async () => {
    logger.info('ğŸ§¹ Starting data cleanup...');
    try {
      await cleanupOldData();
      logger.info('âœ… Data cleanup completed');
    } catch (error) {
      logger.error('âŒ Data cleanup failed:', error);
    }
  });
  
  logger.info('ğŸ“… Background jobs scheduled');
}